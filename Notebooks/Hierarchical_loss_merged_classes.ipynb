{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical loss with merged picea and populus + Acer genus class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "from torchvision.transforms.functional import to_tensor, to_pil_image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels Creation (According to before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "myriam_classes_sp = {'ABBA': 1,\n",
    " 'ACPE': 2,\n",
    " 'ACRU': 3,\n",
    " 'ACSA': 4,\n",
    " 'Acer' : 5,\n",
    " 'BEAL': 6,\n",
    " 'BEPA': 7,\n",
    " 'FAGR': 8,\n",
    " 'LALA': 9,\n",
    " 'Mort': 10,\n",
    " 'Picea': 11,\n",
    " 'PIST': 12,\n",
    " 'Populus': 13,\n",
    " 'THOC': 14,\n",
    " 'TSCA': 15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "myriam_classes_ge = {\"ABBA\": 1, \"Acer_sp\": 2, \"Betula\": 3, \"FAGR\": 4, \"LALA\": 5, \"Mort\": 6, \"Picea\": 7, \"PIST\": 8, \"Populus\": 9, \"THOC\": 10, \"TSCA\": 11}\n",
    "ge_sp_mapping = {1: 1, 2: [2, 3, 4, 5], 3: [6, 7], 4: 8, 5 : 9, 6 : 10, 7: 11, 8: 12, 9: 13, 10: 14, 11: 15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "myriam_classes_fa = {\"Conifer\": 1, \"Non_Conifer\": 2, \"Palm\": 3, \"Mort\": 4}\n",
    "fa_ge_mapping = {1: [1, 7, 8, 10, 11], 2: [2, 3, 4, 9], 3: 5, 4: 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_level_masks(img):\n",
    "    img = np.array(Image.open(img))\n",
    "    \n",
    "    img_sp = make_sp_lvl(img)\n",
    "    img_sp_copy = img_sp.copy()\n",
    "    img_fam = make_fa_lvl(img_sp_copy)\n",
    "    \n",
    "    return Image.fromarray(img_sp), Image.fromarray(img_fam)\n",
    "    \n",
    "def make_sp_lvl(img):\n",
    "    vals_sp = list(ge_sp_mapping.values())\n",
    "    keys_sp = list(ge_sp_mapping.keys())\n",
    "    for sp, gen in zip(keys_sp, vals_sp):\n",
    "        if isinstance(gen, list):\n",
    "            for i in gen:\n",
    "                img[img == i] = sp\n",
    "        else:\n",
    "            img[img == gen] = sp\n",
    "            \n",
    "    return img\n",
    "\n",
    "def make_fa_lvl(img):\n",
    "    vals_fa = list(fa_ge_mapping.values())\n",
    "    keys_fa = list(fa_ge_mapping.keys())\n",
    "    for ge, fam in zip(keys_fa, vals_fa):\n",
    "        if isinstance(fam, list):\n",
    "            for i in fam:\n",
    "                img[img == i] = ge\n",
    "        else:\n",
    "            img[img == fam] = ge\n",
    "            \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilities aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.rand((1, 14, 768, 768))\n",
    "softmax = nn.LogSoftmax(dim=1) #nn.Softmax2d() \n",
    "y_hat = softmax(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genus level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_list = [y_hat[:, 0, :, :],y_hat[:, 1:4, :, :],y_hat[:, 4:6, :, :],y_hat[:, 6, :, :],y_hat[:, 7, :, :], y_hat[:, 8, :, :], y_hat[:, 9, :, :],y_hat[:, 10, :, :],y_hat[:, 11, :, :]\n",
    ",y_hat[:, 12, :, :], y_hat[:, 13, :, :]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768, 768])\n",
      "torch.Size([1, 3, 768, 768])\n",
      "torch.Size([1, 2, 768, 768])\n",
      "torch.Size([1, 768, 768])\n",
      "torch.Size([1, 768, 768])\n",
      "torch.Size([1, 768, 768])\n",
      "torch.Size([1, 768, 768])\n",
      "torch.Size([1, 768, 768])\n",
      "torch.Size([1, 768, 768])\n",
      "torch.Size([1, 768, 768])\n",
      "torch.Size([1, 768, 768])\n"
     ]
    }
   ],
   "source": [
    "for i, tensor in enumerate(y_hat_list):\n",
    "    if len(tensor.shape) == 3:\n",
    "        y_hat_list[i] = tensor.unsqueeze(1)\n",
    "    print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1,\n",
       " 2: [2, 3, 4],\n",
       " 3: [5, 6],\n",
       " 4: 7,\n",
       " 5: 8,\n",
       " 6: 9,\n",
       " 7: 10,\n",
       " 8: 11,\n",
       " 9: 12,\n",
       " 10: 13,\n",
       " 11: 14}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ge_sp_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_probabilites(tensor_list):\n",
    "    first_el = tensor_list[0]\n",
    "    if len(first_el.shape) == 4 and first_el.shape[1] > 1:\n",
    "            first_el = torch.sum(first_el, dim=1).unsqueeze(1)\n",
    "\n",
    "    for tensor in y_hat_list[1:]:\n",
    "        if len(tensor.shape) == 4 and tensor.shape[1] > 1:\n",
    "            tensor = torch.sum(tensor, dim=1).unsqueeze(1)\n",
    "        first_el = torch.cat((first_el, tensor), dim=1)\n",
    "    return first_el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_tensor = aggregate_probabilites(y_hat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 768, 768])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-37.5506, -37.6991, -37.4220,  ..., -37.4855, -37.4066, -37.3186],\n",
      "         [-37.6034, -37.4572, -37.6428,  ..., -37.3591, -37.8006, -37.7853],\n",
      "         [-37.6374, -37.5842, -37.3989,  ..., -37.5589, -37.4889, -37.6028],\n",
      "         ...,\n",
      "         [-37.4531, -37.7999, -37.4906,  ..., -37.5646, -37.3306, -37.4322],\n",
      "         [-37.4706, -37.5696, -37.5055,  ..., -37.4378, -37.4557, -37.2901],\n",
      "         [-37.6603, -37.5226, -37.3923,  ..., -37.3896, -37.4362, -37.6500]]])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(print(sp_tensor.sum(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Family level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "conifer_fa = sp_tensor[:, 0, :, :] + sp_tensor[:, 6, :, :] + sp_tensor[:, 7, :, :] + sp_tensor[:, 9, :, :] + sp_tensor[:, 10, :, :]\n",
    "nonconifera_fa = sp_tensor[:, 1, :, :] + sp_tensor[:, 2, :, :] + sp_tensor[:, 3, :, :] + sp_tensor[:, 8, :, :] \n",
    "palm_fa = sp_tensor[:, 4, :, :]\n",
    "dead_fa = sp_tensor[:, 5, :, :]\n",
    "\n",
    "family_tensor_list = [conifer_fa, nonconifera_fa, palm_fa, dead_fa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768, 768])\n",
      "torch.Size([1, 768, 768])\n",
      "torch.Size([1, 768, 768])\n",
      "torch.Size([1, 768, 768])\n"
     ]
    }
   ],
   "source": [
    "for i, tensor in enumerate(family_tensor_list):\n",
    "    if len(tensor.shape) == 3:\n",
    "        family_tensor_list[i] = tensor.unsqueeze(1)\n",
    "    print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fa_tensor = aggregate_probabilites(family_tensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_tensor = torch.cat((family_tensor_list[0], family_tensor_list[1], family_tensor_list[2], family_tensor_list[3]), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 768, 768])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-37.5506, -37.6991, -37.4220,  ..., -37.4855, -37.4066, -37.3186],\n",
      "         [-37.6034, -37.4572, -37.6428,  ..., -37.3590, -37.8006, -37.7853],\n",
      "         [-37.6374, -37.5842, -37.3989,  ..., -37.5589, -37.4889, -37.6028],\n",
      "         ...,\n",
      "         [-37.4531, -37.7999, -37.4906,  ..., -37.5646, -37.3306, -37.4322],\n",
      "         [-37.4706, -37.5696, -37.5055,  ..., -37.4378, -37.4557, -37.2901],\n",
      "         [-37.6603, -37.5226, -37.3923,  ..., -37.3896, -37.4362, -37.6500]]])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(print(fa_tensor.sum(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Loss Calculation w/ Log-Softmax+NLL Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In implementation for the loss, will need to add the 0th channel (output will have 15 channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "spe_target_tensor = torch.tensor(np.array(Image.open(label_list[1]))).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_target_tensor = torch.tensor(np.array(sp_img)).unsqueeze(0)\n",
    "fam_target_tensor = torch.tensor(np.array(fam_img)).unsqueeze(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=torch.uint8) tensor([0, 1, 2, 3, 4, 5, 6, 7, 9], dtype=torch.uint8) tensor([0, 1, 2, 3, 4], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "print(torch.unique(spe_target_tensor), torch.unique(gen_target_tensor), torch.unique(fam_target_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "spe_preds = y_hat\n",
    "gen_preds = sp_tensor\n",
    "fam_preds = fa_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_sp = nn.NLLLoss()\n",
    "loss_ge = nn.NLLLoss()\n",
    "loss_fa = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 14, 768, 768]) torch.Size([1, 768, 768])\n",
      "torch.Size([1, 11, 768, 768]) torch.Size([1, 768, 768])\n",
      "torch.Size([1, 4, 768, 768]) torch.Size([1, 768, 768])\n"
     ]
    }
   ],
   "source": [
    "print(spe_preds.shape, spe_target_tensor.shape)\n",
    "print(gen_preds.shape, gen_target_tensor.shape)\n",
    "print(fam_preds.shape, fam_target_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_sp = loss_sp(spe_preds, spe_target_tensor.long())\n",
    "output_ge = loss_ge(gen_preds, gen_target_tensor.long())\n",
    "output_fa = loss_fa(fam_preds, fam_target_tensor.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9690) tensor(3.9690)\n"
     ]
    }
   ],
   "source": [
    "print(output_ge, output_ge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating three level labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_path = '/home/mila/v/venkatesh.ramesh/scratch/tree_data/dataset_myriam_split_hierarchical/train/labels'\n",
    "save_path_genus = '/home/mila/v/venkatesh.ramesh/scratch/tree_data/dataset_myriam_split_hierarchical/train/labels_genus'\n",
    "save_path_family = '/home/mila/v/venkatesh.ramesh/scratch/tree_data/dataset_myriam_split_hierarchical/train/labels_family'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical_label_list = glob.glob(train_labels_path + '/**/*.png', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1076"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(hierarchical_label_list[0].replace('labels', 'labels_genus'))\n",
    "len(hierarchical_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1076/1076 [01:15<00:00, 14.27it/s]\n"
     ]
    }
   ],
   "source": [
    "for item in tqdm(hierarchical_label_list):\n",
    "    sp_img, fam_img = create_level_masks(item)\n",
    "    sp_img.save(item.replace('labels', 'labels_genus'))\n",
    "    fam_img.save(item.replace('labels', 'labels_family'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mila/v/venkatesh.ramesh/scratch/tree_data/dataset_myriam_split_hierarchical/train/labels/zone1/1234934_1492306.png'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierarchical_label_list[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1 = Image.open('/home/mila/v/venkatesh.ramesh/scratch/tree_data/dataset_myriam_split_hierarchical/train/labels/zone2/1234948_1492258.png')\n",
    "# x2 = Image.open('/home/mila/v/venkatesh.ramesh/scratch/tree_data/dataset_myriam_split_hierarchical/train/labels_genus/zone2/1234948_1492258.png')\n",
    "# x3 = Image.open('/home/mila/v/venkatesh.ramesh/scratch/tree_data/dataset_myriam_split_hierarchical/train/labels_family/zone2/1234948_1492258.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vis test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/v/venkatesh.ramesh/.conda/envs/ds/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "from torchvision.transforms.functional import to_tensor, to_pil_image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
